{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/BisheshS/sentiment-analysis-yelp/blob/master/sentiment_only_cnn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "8ukr1KUf0cCd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model, Sequential \n",
        "from keras.layers import Input, Activation\n",
        "from keras.layers import LeakyReLU, BatchNormalization\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras import regularizers\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.merge import concatenate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4JyQbyiO0qH4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "1682c9e4-66b9-488e-abcf-7cb3324d74da"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GoseMyZt0tvU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1CE75nQp1BYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "74239d07-33fd-4fb3-f99f-21e1587cccfc"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/Data/train.csv')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5o_khQbH1Efr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_text(x):\n",
        "    try:\n",
        "        x = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", x)\n",
        "        x = re.sub(r\"\\'s\", \" \\'s\", x)\n",
        "        x = re.sub(r\"\\'ve\", \" \\'ve\", x)\n",
        "        x = re.sub(r\"n\\'t\", \" n\\'t\", x)\n",
        "        x = re.sub(r\"\\'re\", \" \\'re\", x)\n",
        "        x = re.sub(r\"\\'d\", \" \\'d\", x)\n",
        "        x = re.sub(r\"\\'ll\", \" \\'ll\", x)\n",
        "        x = re.sub(r\",\", \" , \", x)\n",
        "        x = re.sub(r\"!\", \" ! \", x)\n",
        "        x = re.sub(r\"\\(\", \"\", x)\n",
        "        x = re.sub(r\"\\)\", \"\", x)\n",
        "        x = re.sub(r\"\\?\", \"\", x)\n",
        "        x = re.sub(r\"/\", \"\", x)\n",
        "        x = re.sub(r\"\\s{2,}\", \" \", x)\n",
        "        return x.lower()\n",
        "    except:\n",
        "        return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_bNEHfC1J8w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(clean_text)\n",
        "df = df.dropna(how='any')\n",
        "df['label'] = df['label'].apply(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LkC5gPmm5DR0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer(num_words=2000)\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6x7ngvj5HpQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# calculate the maximum document length\n",
        "def max_length(lines):\n",
        "\treturn max([len(s.split()) for s in lines])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dQngv6Rw5M-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " \n",
        "# encode a list of lines\n",
        "def encode_text(tokenizer, lines, length):\n",
        "\t# integer encode\n",
        "\tencoded = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad encoded sequences\n",
        "\tpadded = pad_sequences(encoded, maxlen=length, padding='post')\n",
        "\treturn padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RUms5O_P5OyL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load training dataset\n",
        "trainLines = df['text'].values \n",
        "trainLabels = df['label'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6HR2P7Zb5Ryb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "7d2aaf9f-c469-46d8-86b5-0547353f32a6"
      },
      "cell_type": "code",
      "source": [
        "# create tokenizer\n",
        "tokenizer = create_tokenizer(trainLines)\n",
        "# calculate max document length\n",
        "length = max_length(trainLines)\n",
        "# calculate vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Max document length: %d' % length)\n",
        "print('Vocabulary size: %d' % vocab_size)\n",
        "trainX = encode_text(tokenizer, trainLines, length)\n",
        "print(trainX.shape)\n",
        "print(trainLabels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max document length: 1093\n",
            "Vocabulary size: 186218\n",
            "(400000, 1093)\n",
            "[1 2 2 ... 2 2 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RFRZ55yo5UwK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(trainX,trainLabels, test_size = 0.33, random_state = 42)\n",
        "Y_train = np_utils.to_categorical(Y_train)\n",
        "Y_test = np_utils.to_categorical(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63PgvdqU5mRr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def define_model(lenght, vocal_size):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(vocab_size, 100, input_length=length))\n",
        "    \n",
        "    model.add(Conv1D(filters=256, kernel_size=4, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Conv1D(filters=256, kernel_size=4, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(MaxPooling1D())\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv1D(filters=128, kernel_size=4, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Conv1D(filters=128, kernel_size=4, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(MaxPooling1D())\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv1D(filters=64, kernel_size=4, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Conv1D(filters=64, kernel_size=4, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(MaxPooling1D())\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# summarize\n",
        "    print(model.summary())\n",
        "\t#plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4cVk2zMk5dTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1246
        },
        "outputId": "dcc8a121-2d06-4b93-81fa-5f32b96f14ee"
      },
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = define_model(length, 3000)\n",
        "# fit model\n",
        "#model.fit([X_train,X_train,X_train], array(Y_train), epochs=10, batch_size=200)\n",
        "model.fit(X_train, array(Y_train), validation_data=(X_test, Y_test), epochs=5, batch_size=200)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 1093, 100)         18621800  \n",
            "_________________________________________________________________\n",
            "conv1d_21 (Conv1D)           (None, 1093, 256)         102656    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 1093, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 1093, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv1d_22 (Conv1D)           (None, 1093, 256)         262400    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 1093, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 1093, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling (None, 546, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_23 (Conv1D)           (None, 546, 128)          131200    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 546, 128)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 546, 128)          512       \n",
            "_________________________________________________________________\n",
            "conv1d_24 (Conv1D)           (None, 546, 128)          65664     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)   (None, 546, 128)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 546, 128)          512       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_11 (MaxPooling (None, 273, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_25 (Conv1D)           (None, 273, 64)           32832     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 273, 64)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 273, 64)           256       \n",
            "_________________________________________________________________\n",
            "conv1d_26 (Conv1D)           (None, 273, 64)           16448     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 273, 64)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 273, 64)           256       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_12 (MaxPooling (None, 136, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 136, 64)           0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 8704)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                87050     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 33        \n",
            "=================================================================\n",
            "Total params: 19,323,667\n",
            "Trainable params: 19,321,875\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 268000 samples, validate on 132000 samples\n",
            "Epoch 1/5\n",
            "  4600/268000 [..............................] - ETA: 18:28 - loss: 0.5758 - acc: 0.7388"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "267800/268000 [============================>.] - ETA: 0s - loss: 0.2254 - acc: 0.9046"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r268000/268000 [==============================] - 1150s 4ms/step - loss: 0.2254 - acc: 0.9046 - val_loss: 0.1751 - val_acc: 0.9318\n",
            "Epoch 2/5\n",
            " 63400/268000 [======>.......................] - ETA: 12:45 - loss: 0.1565 - acc: 0.9376"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "268000/268000 [==============================] - 1148s 4ms/step - loss: 0.1565 - acc: 0.9379 - val_loss: 1.2554 - val_acc: 0.8543\n",
            "Epoch 3/5\n",
            "  9200/268000 [>.............................] - ETA: 16:08 - loss: 0.1420 - acc: 0.9455"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "267800/268000 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9443"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r268000/268000 [==============================] - 1147s 4ms/step - loss: 0.1421 - acc: 0.9443 - val_loss: 0.2501 - val_acc: 0.9130\n",
            "Epoch 4/5\n",
            " 63400/268000 [======>.......................] - ETA: 12:45 - loss: 0.1276 - acc: 0.9502"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "268000/268000 [==============================] - 1147s 4ms/step - loss: 0.1321 - acc: 0.9480 - val_loss: 0.1763 - val_acc: 0.9322\n",
            "Epoch 5/5\n",
            "  9200/268000 [>.............................] - ETA: 16:06 - loss: 0.1177 - acc: 0.9567"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "267800/268000 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9526"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r268000/268000 [==============================] - 1146s 4ms/step - loss: 0.1229 - acc: 0.9525 - val_loss: 0.1603 - val_acc: 0.9392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa8471f1940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "UJlwnah_6M16",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c5e2426-4574-4e45-d9e9-7d8e6ce3a7d6"
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"CNN ACC: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN ACC: 93.92%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KYav1j3e-und",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/Data/model_moring.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rVsGNC7--xbd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "4dd37e19-3715-4f48-ee9e-0b87eb376de8"
      },
      "cell_type": "code",
      "source": [
        "tokenizer.dump('/content/drive/Data/tokenizer.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-ad621a036076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/Data/tokenizer.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tokenizer' object has no attribute 'dump'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uVUduY-cnE3Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('/content/drive/Data/tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A89lBR4on38F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}